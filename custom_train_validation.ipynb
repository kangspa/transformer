{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa319325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en\n",
    "# !python -m spacy download de\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"wmt14_translate_de-en_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc51c377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë…ì¼ì–´ í† í° ìµœëŒ€ ê¸¸ì´: 75\n",
      "ì˜ì–´ í† í° ìµœëŒ€ ê¸¸ì´: 92\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "\n",
    "# ë…ì¼ì–´(Deutsch) ë¬¸ì¥ì„ í† í°í™” í•˜ëŠ” í•¨ìˆ˜\n",
    "def tokenize_de(text):\n",
    "    return [token.text for token in spacy_de.tokenizer(text)]\n",
    "de_token = data['de'].apply(tokenize_de)\n",
    "\n",
    "# ì˜ì–´(English) ë¬¸ì¥ì„ í† í°í™” í•˜ëŠ” í•¨ìˆ˜\n",
    "def tokenize_en(text):\n",
    "    return [token.text for token in spacy_en.tokenizer(text)]\n",
    "en_token = data['en'].apply(tokenize_en)\n",
    "\n",
    "de_max_len = de_token.apply(len).max()\n",
    "en_max_len = en_token.apply(len).max()\n",
    "print(\"ë…ì¼ì–´ í† í° ìµœëŒ€ ê¸¸ì´:\", de_max_len)\n",
    "print(\"ì˜ì–´ í† í° ìµœëŒ€ ê¸¸ì´:\", en_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea8cf2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë…ì¼ì–´ í† í° ì‚¬ì „ í¬ê¸°: 13941\n",
      "ì˜ì–´ í† í° ì‚¬ì „ í¬ê¸°: 10242\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# ë…ì¼ì–´(Deutsch) ì‚¬ì „ ì œì‘\n",
    "de_dict = defaultdict(list)\n",
    "de_dict[\"<unk>\"] = 0\n",
    "de_dict[\"<pad>\"] = 1\n",
    "de_dict[\"<sos>\"] = 2\n",
    "de_dict[\"<eos>\"] = 3\n",
    "idx = 4\n",
    "for token_list in de_token:\n",
    "    for token in token_list:\n",
    "        if token not in de_dict:\n",
    "            de_dict[token] = idx\n",
    "            idx += 1\n",
    "print(\"ë…ì¼ì–´ í† í° ì‚¬ì „ í¬ê¸°:\", len(de_dict))\n",
    "\n",
    "# ì˜ì–´(English) í† í°ì„ ìˆ«ì ì¸ë±ìŠ¤ë¡œ ë³€í™˜\n",
    "en_dict = defaultdict(list)\n",
    "en_dict[\"<unk>\"] = 0\n",
    "en_dict[\"<pad>\"] = 1\n",
    "en_dict[\"<sos>\"] = 2\n",
    "en_dict[\"<eos>\"] = 3\n",
    "idx = 4\n",
    "for token_list in en_token:\n",
    "    for token in token_list:\n",
    "        if token not in en_dict:\n",
    "            en_dict[token] = idx\n",
    "            idx += 1\n",
    "print(\"ì˜ì–´ í† í° ì‚¬ì „ í¬ê¸°:\", len(en_dict))\n",
    "\n",
    "dict_en = {v: k for k, v in en_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d63b6e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13941 94\n"
     ]
    }
   ],
   "source": [
    "# ìµœëŒ€ ì‚¬ì „ í¬ê¸° (input_dim ê°’ ì„¤ì •)\n",
    "VOCAB_SIZE = max(len(de_dict), len(en_dict))\n",
    "# Maximum sequence length\n",
    "MAX_LEN = max(de_max_len, en_max_len) + 2\n",
    "\n",
    "# ë…ì¼ì–´(Deutsch) í† í°ì„ ìˆ«ì ì¸ë±ìŠ¤ë¡œ ë³€í™˜\n",
    "de_vocab = []\n",
    "for token_list in de_token:\n",
    "    tmp = [2] # ì‹œì‘ í† í° ì¶”ê°€\n",
    "    for token in token_list:\n",
    "        tmp.append(de_dict[token])\n",
    "    tmp.append(3) # ì¢…ë£Œ í† í° ì¶”ê°€\n",
    "    # íŒ¨ë”© ì²˜ë¦¬\n",
    "    if len(tmp) < MAX_LEN:\n",
    "        tmp += [1] * (MAX_LEN - len(tmp))\n",
    "    de_vocab.append(tmp)\n",
    "\n",
    "# ì˜ì–´(English) í† í°ì„ ìˆ«ì ì¸ë±ìŠ¤ë¡œ ë³€í™˜\n",
    "en_vocab = []\n",
    "for token_list in en_token:\n",
    "    tmp = [2] # ì‹œì‘ í† í° ì¶”ê°€\n",
    "    for token in token_list:\n",
    "        tmp.append(en_dict[token])\n",
    "    tmp.append(3) # ì¢…ë£Œ í† í° ì¶”ê°€\n",
    "    # íŒ¨ë”© ì²˜ë¦¬\n",
    "    if len(tmp) < MAX_LEN:\n",
    "        tmp += [1] * (MAX_LEN - len(tmp))\n",
    "    en_vocab.append(tmp)\n",
    "\n",
    "print(VOCAB_SIZE, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f954700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "seed = 2025\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d6d98fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "input_dim = VOCAB_SIZE\n",
    "seq_len = MAX_LEN\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "dropout = 0.1\n",
    "d_ffn=2048\n",
    "\n",
    "betas = (0.9, 0.98)\n",
    "eps = 1e-9\n",
    "\n",
    "warmup_steps = 4000\n",
    "lrate = lambda step: 0 if step == 0 else (d_model ** -0.5) * min(step ** -0.5, step * warmup_steps ** -1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc25d70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(de_vocab, en_vocab, test_size = 0.2, random_state = seed)\n",
    "\n",
    "x_train = torch.LongTensor(x_train)\n",
    "x_valid = torch.LongTensor(x_valid)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_valid = torch.LongTensor(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85e3043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "valid_dataset = TensorDataset(x_valid, y_valid)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom_transformer2\n",
    "model = custom_transformer2.Transformer(input_dim, seq_len, d_model, num_heads, num_layers, dropout, d_ffn, en_dict['<pad>'], device).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), betas=betas, eps=eps)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lrate)\n",
    "\n",
    "# <pad> í† í°ì€ ë¬´ì‹œí•´ì•¼í•œë‹¤.\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=1, label_smoothing=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c71628d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "[Epoch:   10] cost = 9.66373975\n",
      "[GPU] Allocated: 1335.86MB | Reserved: 5560.00MB\n",
      "[Time] 27.91 sec\n",
      "##############################\n",
      "[Epoch:   20] cost = 9.33843056\n",
      "[GPU] Allocated: 1335.86MB | Reserved: 5560.00MB\n",
      "[Time] 31.69 sec\n",
      "##############################\n",
      "[Epoch:   30] cost = 8.9292417\n",
      "[GPU] Allocated: 1335.86MB | Reserved: 5560.00MB\n",
      "[Time] 31.50 sec\n",
      "##############################\n",
      "[Epoch:   40] cost = 8.63359871\n",
      "[GPU] Allocated: 1335.86MB | Reserved: 5560.00MB\n",
      "[Time] 31.50 sec\n",
      "##############################\n",
      "[Epoch:   50] cost = 8.46960271\n",
      "[GPU] Allocated: 1335.86MB | Reserved: 5560.00MB\n",
      "[Time] 31.58 sec\n",
      "##############################\n",
      "[Epoch:   60] cost = 8.35601381\n",
      "[GPU] Allocated: 1335.86MB | Reserved: 5560.00MB\n",
      "[Time] 31.32 sec\n",
      "##############################\n",
      "[Epoch:   70] cost = 8.23938568\n",
      "[GPU] Allocated: 1335.86MB | Reserved: 5560.00MB\n",
      "[Time] 31.37 sec\n",
      "##############################\n",
      "[Epoch:   80] cost = 8.11401133\n",
      "[GPU] Allocated: 1335.86MB | Reserved: 5560.00MB\n",
      "[Time] 27.47 sec\n",
      "##############################\n",
      "[Epoch:   90] cost = 8.00423733\n",
      "[GPU] Allocated: 1335.86MB | Reserved: 5560.00MB\n",
      "[Time] 27.67 sec\n",
      "##############################\n",
      "[Epoch:  100] cost = 7.89566513\n",
      "[GPU] Allocated: 1335.86MB | Reserved: 5560.00MB\n",
      "[Time] 27.60 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "total_batch = len(data_loader)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    avg_cost = 0\n",
    "    \n",
    "    model.train()    \n",
    "    for X, Y in data_loader:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X, Y[:, :-1])\n",
    "        cost = criterion(hypothesis.transpose(1, 2), Y[:, 1:])\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        avg_cost += cost.item() / total_batch\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(\"#\" * 30)\n",
    "        print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n",
    "        allocated = torch.cuda.memory_allocated() / (1024 ** 2)\n",
    "        reserved = torch.cuda.memory_reserved() / (1024 ** 2)\n",
    "        print(f\"[GPU] Allocated: {allocated:.2f}MB | Reserved: {reserved:.2f}MB\")\n",
    "        print(f\"[Time] {time.time() - start_time:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54162cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "[Valid] cost = 7.8903177\n",
      "[Valid] BLEU = 1.28\n",
      "[GPU] Allocated: 1969.02MB | Reserved: 5560.00MB\n",
      "[Time] 121.44 sec\n",
      "##############################\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "smoothie = SmoothingFunction().method4\n",
    "\n",
    "model.eval()\n",
    "start_time = time.time()\n",
    "total_valid_cost = 0\n",
    "bleu_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, Y in valid_loader:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        # --- 1. Validation Loss ê³„ì‚° (Teacher Forcing ë°©ì‹ ìœ ì§€) ---\n",
    "        # ëª¨ë¸ì— ì •ë‹µì„ ì•Œë ¤ì£¼ë©° ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡ ëŠ¥ë ¥ì„ í‰ê°€\n",
    "        hypothesis_for_loss = model(X, Y[:, :-1])\n",
    "        cost = criterion(hypothesis_for_loss.transpose(1, 2), Y[:, 1:])\n",
    "        total_valid_cost += cost.item() / len(valid_loader)\n",
    "\n",
    "        # --- 2. BLEU ì ìˆ˜ ê³„ì‚°ì„ ìœ„í•œ ë¬¸ì¥ ìƒì„± (Auto-Regressive ë°©ì‹) ---\n",
    "        # ëª¨ë¸ ìŠ¤ìŠ¤ë¡œ ë¬¸ì¥ì„ ìƒì„±í•˜ëŠ” ëŠ¥ë ¥ì„ í‰ê°€\n",
    "\n",
    "        # <sos> í† í°ìœ¼ë¡œ ì‹œì‘\n",
    "        trg_input = torch.full((batch_size, 1), 2, dtype=torch.long, device=device)\n",
    "\n",
    "        for _ in range(MAX_LEN - 1):\n",
    "            hypothesis_for_bleu = model(X, trg_input)\n",
    "            pred_token = hypothesis_for_bleu.argmax(dim=-1)[:, -1].unsqueeze(1)\n",
    "            trg_input = torch.cat((trg_input, pred_token), dim=1)\n",
    "\n",
    "        # ğŸ” ë””ì½”ë”© í›„ BLEU ê³„ì‚°\n",
    "        for i in range(batch_size):\n",
    "            predicted_sentence = trg_input[i].cpu()\n",
    "            target_sentence = Y[i, 1:].cpu()\n",
    "\n",
    "            pred_tokens = [dict_en.get(token_id.item(), \"<unk>\") for token_id in predicted_sentence]\n",
    "            target_tokens = [dict_en.get(token_id.item(), \"<unk>\") for token_id in target_sentence]\n",
    "            \n",
    "            # <eos> í† í° ì´í›„ëŠ” ì˜ë¼ë‚´ì–´ ë” ì •í™•í•œ BLEU ì ìˆ˜ ê³„ì‚° (ê°œì„  ì‚¬í•­)\n",
    "            try:\n",
    "                eos_idx = pred_tokens.index('<eos>')\n",
    "                pred_tokens = pred_tokens[:eos_idx]\n",
    "            except ValueError: pass # <eos>ê°€ ì—†ëŠ” ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "            try:\n",
    "                eos_idx = target_tokens.index('<eos>')\n",
    "                target_tokens = target_tokens[:eos_idx]\n",
    "            except ValueError: pass\n",
    "\n",
    "            bleu = sentence_bleu(\n",
    "                [target_tokens], pred_tokens,\n",
    "                weights=(0.25, 0.25, 0.25, 0.25),\n",
    "                smoothing_function=smoothie\n",
    "            )\n",
    "            bleu_scores.append(bleu)\n",
    "\n",
    "avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "print(\"#\" * 30)\n",
    "print('[Valid] cost = {:>.9}'.format(total_valid_cost))\n",
    "print('[Valid] BLEU = {:.2f}'.format(avg_bleu * 100))\n",
    "allocated = torch.cuda.memory_allocated() / (1024 ** 2)\n",
    "reserved = torch.cuda.memory_reserved() / (1024 ** 2)\n",
    "print(f\"[GPU] Allocated: {allocated:.2f}MB | Reserved: {reserved:.2f}MB\")\n",
    "print(f\"[Time] {time.time() - start_time:.2f} sec\")\n",
    "print(\"#\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
